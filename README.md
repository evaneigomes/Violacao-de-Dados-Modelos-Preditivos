
## MVP ‚Äì Ci√™ncia de Dados: An√°lise Preditiva para Viola√ß√£o de Dados - Uma abordagem comparativa entre Modelos

**Discente:** *\[Evanei Gomes dos Santos]*

**Docente:** *\[Andre Luiz Marques Serrano]*

**Data:** *\[28/09/2025]*


---

## 1. Defini√ß√£o do Problema

Organiza√ß√µes p√∫blicas e privadas enfrentam um aumento de **viola√ß√µes de dados**, expondo informa√ß√µes sens√≠veis e causando preju√≠zos financeiros e danos √† reputa√ß√£o. O custo m√©dio de uma viola√ß√£o de dados, segundo a IBM Security, √© de **US$ 4,88 milh√µes**. Esses incidentes n√£o s√£o aleat√≥rios, mas seguem **padr√µes temporais e setoriais** que, se compreendidos, podem ajudar a antecipar picos e otimizar a preven√ß√£o e a resposta.

Este MVP busca prever a quantidade mensal de viola√ß√µes de dados por tipo de organiza√ß√£o (ex.: sa√∫de, varejo, governo), a partir de s√©ries temporais hist√≥ricas (2010‚Äì2023) extra√≠das do dataset Privacy Rights Clearinghouse ‚Äì Data Breach Chronology

* **Prophet (Meta/Facebook)** ‚Äì modelo estat√≠stico aditivo, robusto para sazonalidade.
* **ARIMA/SARIMA** ‚Äì modelo estat√≠stico cl√°ssico para s√©ries temporais.
* **XGBoost Regressor** ‚Äì modelo de aprendizado de m√°quina baseado em √°rvores de decis√£o (Gradient Boosting).

O estudo atende aos objetivos do **MVP/Prova 1 do Programa de P√≥s-Gradua√ß√£o Profissional em Engenharia El√©trica (PPEE/UnB)** e faz parte de uma linha de pesquisa sobre **ciberseguran√ßa e predi√ß√£o de incidentes**, fundamentando-se em **modelos comparativos** para auxiliar **estrat√©gias de mitiga√ß√£o de riscos e pol√≠ticas de seguran√ßa da informa√ß√£o**.

Hip√≥tese

As tend√™ncias hist√≥ricas de viola√ß√µes de dados, agregadas mensalmente por setor organizacional, cont√™m informa√ß√µes suficientes para gerar previs√µes confi√°veis sobre incidentes futuros.
O uso de modelos de s√©ries temporais e de aprendizado de m√°quina permite reduzir o erro de previs√£o (MAPE) para n√≠veis aceit√°veis (< 20%) em setores com maior regularidade hist√≥rica.

---

## 2. Dataset

**Fonte:** [Privacy Rights Clearinghouse ‚Äì Data Breach Chronology](https://privacyrights.org)
**Per√≠odo:** **2010 ‚Äì 2023** (registros anteriores a 2010 foram desconsiderados por baixa consist√™ncia)
**Periodicidade:** agrega√ß√£o **mensal (ME)** para as s√©ries temporais.

**Atributos Principais:**

| Coluna        | Descri√ß√£o                                                     |
| ------------- | ------------------------------------------------------------- |
| `Date Breach` | Data do incidente                                             |
| `BSF`         | Servi√ßos financeiros                                          |
| `BSO`         | Outros neg√≥cios (TI, manufatura, servi√ßos)                    |
| `BSR`         | Varejo (lojas f√≠sicas e online)                               |
| `EDU`         | Educa√ß√£o (escolas, universidades)                             |
| `GOV`         | Governo e for√ßas armadas                                      |
| `MED`         | Sa√∫de (hospitais, cl√≠nicas)                                   |
| `NGO`         | Organiza√ß√µes sem fins lucrativos                              |
| `UNKN`        | Setor desconhecido (n√£o classificado por falta de informa√ß√£o) |
| `Total Geral` | Soma de todos os setores                                      |

**Pr√©-Processamento:**

* Ajuste de datas incompletas: descartadas datas apenas com ano (`YYYY`), e datas `YYYY-MM` assumiram dia 1.
* Filtro temporal aplicado: `2010-01-01` a `2023-12-31`.
* Reamostragem mensal: `df.resample('ME').sum()`.
* Tratamento de **outliers** via **IQR (Interquartile Range)** para maior robustez dos modelos.
* C√°lculo do **Expoente de Hurst** para avaliar persist√™ncia ou aleatoriedade das s√©ries.

---

### Configura√ß√£o do Ambiente (Python/Colab)

```python
# Bibliotecas principais
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Modelos e m√©tricas
from prophet import Prophet                # Modelo Prophet (Meta/Facebook)
from statsmodels.tsa.statespace.sarimax import SARIMAX  # ARIMA/SARIMA
from xgboost import XGBRegressor           # Modelo XGBoost
from sklearn.metrics import mean_absolute_error, mean_squared_error

# Configura√ß√£o de visualiza√ß√£o
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (12, 6)

print("‚úÖ Ambiente configurado e bibliotecas importadas com sucesso!")
```


---

## 3. Ambiente e Depend√™ncias

**Linguagem:** Python **3.10+**
**IDE recomendada:** [Google Colab](https://colab.research.google.com/) ‚Äì para execu√ß√£o interativa em nuvem.

### Instala√ß√£o das Depend√™ncias

```bash
pip install prophet statsmodels xgboost scikit-learn pandas numpy matplotlib seaborn openpyxl
```

### Principais Bibliotecas Utilizadas

* **prophet** ‚Äì modelo estat√≠stico aditivo para s√©ries temporais.
* **statsmodels** ‚Äì implementa√ß√£o do **ARIMA/SARIMA**.
* **xgboost** ‚Äì regress√£o baseada em *gradient boosting* para padr√µes n√£o lineares.
* **scikit-learn** ‚Äì m√©tricas (MAE, RMSE, MAPE) e fun√ß√µes auxiliares.
* **pandas / numpy** ‚Äì ETL e manipula√ß√£o num√©rica.
* **matplotlib / seaborn** ‚Äì visualiza√ß√µes gr√°ficas e heatmaps.
* **openpyxl** ‚Äì leitura e escrita de arquivos Excel.

### Configura√ß√£o de Estilo dos Gr√°ficos

```python
import matplotlib.pyplot as plt
import seaborn as sns

# Estilo visual
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (12, 6)
plt.rcParams['axes.labelweight'] = 'bold'
plt.rcParams['axes.titleweight'] = 'bold'

print("‚úÖ Ambiente configurado com sucesso!")
```

> üí° O ambiente foi validado no **Google Colab** e √© compat√≠vel com ambientes locais que utilizem Python 3.10 ou superior.

---

## 4. Prepara√ß√£o dos Dados

1. **Leitura direta** do arquivo (Excel/Google Sheets).
2. **Ajuste de datas incompletas** (`YYYY` ‚Üí descartado; `YYYY-MM` ‚Üí assumido dia 1).
3. **Filtro temporal:** `2010-01-01` a `2023-12-31`.
4. **Reamostragem mensal:** `df.resample('ME').sum()`.
5. **Tratamento de valores ausentes/outliers** e aplica√ß√£o do **expoente de Hurst** para avaliar persist√™ncia ou aleatoriedade das s√©ries.

---

## 5. Metodologia e Modelos

* **Treino:** todas as observa√ß√µes **exceto as √∫ltimas 24 meses**
* **Teste:** **√∫ltimas 24 meses** (2022-2023)
* **Grid Search** para ajuste de hiperpar√¢metros de cada modelo

### a) Prophet

* `changepoint_prior_scale` ‚àà {0.05, 0.1, 0.3, 0.5}
* `fourier_order` ‚àà {5, 10, 15}
* `n_changepoints` ‚àà {25, 50}

### b) ARIMA/SARIMA

* Ordens n√£o sazonais `(p,d,q)` e sazonais `(P,D,Q,s)` com sazonalidade 12

### c) XGBoost Regressor

* `n_estimators`, `max_depth`, `learning_rate` otimizados por grid search

---

## 6. M√©tricas de Avalia√ß√£o

Foram utilizadas tr√™s m√©tricas cl√°ssicas:

* **MAE** (Mean Absolute Error)
* **RMSE** (Root Mean Square Error)
* **MAPE (%)** (Mean Absolute Percentage Error) ‚Äì **m√©trica principal** por permitir compara√ß√£o relativa entre setores.

De acordo com **Lewis (1982)**:

* **MAPE < 10%:** Alta precis√£o
* **10 ‚â§ MAPE < 20%:** Boa precis√£o
* **20 ‚â§ MAPE < 50%:** Precis√£o razo√°vel
* **MAPE ‚â• 50%:** Previs√£o imprecisa

---

## 7. Execu√ß√£o do Projeto

1. Abrir o notebook **`OrganizationType_Prophet_x_Arima_x_Xgboost_v2.ipynb`** no Colab.
2. Instalar as depend√™ncias listadas.
3. Carregar o dataset.
4. Executar as c√©lulas na sequ√™ncia:

   * Pr√©-processamento e reamostragem
   * Ajuste e treino dos modelos (Prophet √ó ARIMA √ó XGBoost)
   * Compara√ß√£o de m√©tricas
   * Visualiza√ß√µes (gr√°ficos Real √ó Previsto e heatmap comparativo)
5. Resultados exportados em CSV:

   * `resultados_prophet_gridsearch.csv`
   * `resultados_arima_gridsearch.csv`
   * `melhores_resultados_xgboost.csv`

---

## 8. Resultados Principais

O desempenho foi avaliado por **MAPE (%)** para cada setor e modelo.

> üîé Observa√ß√µes:
>
> * **XGBoost** apresentou **menores MAPE em setores como Total Geral (5,97%) e UNKN (10,03%)**, obtendo **boa/alta precis√£o**.
> * **Prophet** teve performance intermedi√°ria, com destaque para **MED (26,54%)** e **Total Geral (17,63%)** (boa precis√£o).
> * **ARIMA** obteve MAPE mais altos, sendo competitivo apenas em **EDU (36,74%)**.
> * O **setor BSR (Varejo)** foi o mais desafiador (MAPE ‚â• 70% em todos os modelos ‚Äì previs√£o imprecisa).

---

## 9. Conclus√£o

A an√°lise evidencia que **a m√©trica MAPE foi determinante para identificar a acur√°cia relativa entre setores e modelos**, validando achados do artigo de refer√™ncia.

* O **XGBoost** se destacou por **menor erro percentual em setores agregados (Total Geral e UNKN)**, tornando-se mais indicado para s√©ries com maior volume e padr√µes suaves.
* O **Prophet** apresentou **desempenho consistente em setores com sazonalidade clara (MED, EDU)**.
* O **ARIMA** mostrou-se mais limitado em cen√°rios complexos ou de alta variabilidade.
* O **MAPE elevado no BSR** sugere **alta volatilidade no varejo**, exigindo abordagens mais sofisticadas (ex.: redes neurais LSTM/TCN, conforme evid√™ncias do artigo original).

Esses resultados refor√ßam a import√¢ncia da **sele√ß√£o contextual do modelo** e demonstram como m√©tricas interpret√°veis, como **MAPE**, orientam a **tomada de decis√£o em pol√≠ticas de seguran√ßa cibern√©tica**.

> **Perspectivas Futuras:** incorporar **modelos de deep learning (LSTM, TCN)**, explorar **previs√£o por tipo de vazamento** e **expandir a an√°lise para bases globais**, alinhando-se √†s recomenda√ß√µes de trabalhos recentes.

---

## 10. Estrutura do Reposit√≥rio

```
‚îú‚îÄ‚îÄ OrganizationType_Prophet_x_Arima_x_Xgboost_v2.ipynb
‚îú‚îÄ‚îÄ resultados_prophet_gridsearch.csv
‚îú‚îÄ‚îÄ resultados_arima_gridsearch.csv
‚îú‚îÄ‚îÄ melhores_resultados_xgboost.csv
‚îú‚îÄ‚îÄ imagens/
‚îÇ   ‚îî‚îÄ‚îÄ heatmap_mape.jpg
‚îî‚îÄ‚îÄ README.md
```

---

**Autor:** Evanei Gomes dos Santos ‚Äì PPEE/UnB 2025
[evanei.santos@aluno.unb.br](mailto:evanei.santos@aluno.unb.br)

---

